{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f778fcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=6)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from prep_data import get_eng_hi_dataset\n",
    "from transformers import GPT2LMHeadModel, MT5Tokenizer\n",
    "\n",
    "torch.seed(42)\n",
    "\n",
    "device = torch.device('cuda:6' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932d4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(nn.Module):\n",
    "    def __init__(self, model) -> None:\n",
    "        super(LLM, self).__init__()\n",
    "        self._model = model\n",
    "        self.hidden_size = model.config.hidden_size\n",
    "        self.embed_size = model.config.hidden_size\n",
    "        self.n_layers = model.config.num_hidden_layers\n",
    "        self.n_heads = model.config.num_attention_heads\n",
    "        self.head_size = self.embed_size // self.n_heads\n",
    "\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=2)\n",
    "        self.logSoftmax_1 = nn.LogSoftmax(dim=1)\n",
    "        self.nll = nn.NLLLoss()\n",
    "\n",
    "\n",
    "    def encode(self, input_ids, input_mask):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        len_sent = input_ids.shape[1]\n",
    "        attn_mask = input_mask\n",
    "\n",
    "        outputs = self._model(input_ids, \n",
    "                              attention_mask=attn_mask,  \n",
    "                              use_cache=True)\n",
    "\n",
    "        #RE-ENCODING\n",
    "        layer_prefix_list = []\n",
    "        attn_mask = torch.cat([input_mask, input_mask], dim=1)\n",
    "\n",
    "        outputs = self._model(input_ids, \n",
    "                              past_key_values=outputs.past_key_values, \n",
    "                              attention_mask=attn_mask, \n",
    "                              use_cache=True)\n",
    "        \n",
    "        past_key_values = []\n",
    "        for (key, value) in outputs.past_key_values:\n",
    "            k = key[:,:,len_sent:,:]\n",
    "            v = value[:,:,len_sent:,:]\n",
    "            past_key_values.append((k, v))\n",
    "\n",
    "        return past_key_values\n",
    "    \n",
    "    def decode(self, target_ids, input_mask, target_mask, past_key_values, mode='train'):\n",
    "        batch_size = target_ids.shape[0]\n",
    "        attn_mask = torch.cat([input_mask, target_mask], dim=1)\n",
    "\n",
    "        outputs = self._model(target_ids, \n",
    "                              past_key_values=past_key_values, \n",
    "                              attention_mask=attn_mask,  \n",
    "                              use_cache=True)\n",
    "        return outputs.logits, outputs.past_key_values\n",
    "    \n",
    "    def forward(self, input_ids, input_mask, target_ids, target_mask):\n",
    "        past_key_values = self.encode(input_ids, input_mask)\n",
    "        labels = target_ids[:, 1:]\n",
    "        target_ids = target_ids[:, :-1]\n",
    "        target_mask = target_mask[:, :-1]\n",
    "        logits,_ = self.decode(target_ids, input_mask, target_mask, past_key_values)\n",
    "\n",
    "        # make batch size and sentence length as one dimension\n",
    "        logprobs = self.logSoftmax(logits)\n",
    "        logprobs = logprobs.reshape([logprobs.shape[0] * logprobs.shape[1], -1])\n",
    "        target_mask = target_mask.reshape([target_mask.shape[0] * target_mask.shape[1],])\n",
    "        labels = labels.flatten()\n",
    "        loss = -logprobs[torch.arange(logprobs.shape[0], device=labels.device), labels]\n",
    "#         print(loss.shape, target_mask.shape)\n",
    "        loss = torch.sum(loss * target_mask) / torch.sum(target_mask)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe6ea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/cfilt___parquet/cfilt--iitb-english-hindi-911387c6837f8b91/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a151c0af895e4e399ed62a2d5989219b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_data(PATH):\n",
    "    dataset = []\n",
    "    f_en = open(PATH + 'filtered.en', 'r')\n",
    "    for line in f_en.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        entry = {'en': line}\n",
    "        dataset.append(entry)\n",
    "    f_en.close()\n",
    "    \n",
    "    f_hi = open(PATH + 'filtered.hi', 'r')\n",
    "    for i, line in enumerate(f_hi.readlines()):\n",
    "        line = line.strip('\\n')\n",
    "        dataset[i]['hi'] = line\n",
    "    f_hi.close()\n",
    "    return dataset\n",
    "\n",
    "val_data, test_data = get_eng_hi_dataset()\n",
    "train_data = read_data('filtered_data/')\n",
    "train_data = train_data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "171684bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelCorpus(Dataset):\n",
    "    def __init__(self, data, src_lang='en', tgt_lang='hi') -> None:\n",
    "        super(ParallelCorpus, self).__init__()\n",
    "        self.src = []\n",
    "        self.tgt = []\n",
    "        for pair in data:\n",
    "            self.src.append(pair[src_lang])\n",
    "            self.tgt.append(pair[tgt_lang])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.src[index], self.tgt[index]\n",
    "\n",
    "train_pc = ParallelCorpus(train_data, src_lang='en', tgt_lang='hi')\n",
    "test_pc = ParallelCorpus(test_data, src_lang='en', tgt_lang='hi')\n",
    "val_pc = ParallelCorpus(val_data, src_lang='en', tgt_lang='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ffaf9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_prefix = 100\n",
    "lr = 1e-4\n",
    "batch_size = 4\n",
    "num_epochs = 2\n",
    "token_limit = ((1023 - len_prefix) // 2) - 3  #to accomodate extra one token if max_len=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1121c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_pc, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_pc, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_pc, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9332b653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'T5Tokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MT5Tokenizer.from_pretrained(\"THUMT/mGPT\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"THUMT/mGPT\")\n",
    "\n",
    "MT_model = LLM(model).to(device)\n",
    "optimizer = torch.optim.Adam(params=MT_model.parameters(),lr=lr, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------EPOCH 1-------------------------------\n",
      "Step 500 | Val Loss: 3.35807| Best val loss: 3.35807 | Time:  0.1360 hrs\n",
      "Step 1000 | Val Loss: 3.44138| Best val loss: 3.35807 | Time:  0.2923 hrs\n",
      "Step 1500 | Val Loss: 3.28490| Best val loss: 3.28490 | Time:  0.4492 hrs\n",
      "Step 2000 | Val Loss: 3.36685| Best val loss: 3.28490 | Time:  0.6118 hrs\n",
      "Step 2500 | Val Loss: 3.20250| Best val loss: 3.20250 | Time:  0.7688 hrs\n",
      "Step 3000 | Val Loss: 3.32183| Best val loss: 3.20250 | Time:  0.9311 hrs\n",
      "Step 3500 | Val Loss: 3.18532| Best val loss: 3.18532 | Time:  1.0907 hrs\n",
      "Step 4000 | Val Loss: 3.06976| Best val loss: 3.06976 | Time:  1.2529 hrs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation():\n",
    "    total_loss = 0\n",
    "    for i, (src, tgt) in enumerate(val_loader):\n",
    "        max_src_len = min(token_limit, max([len(s) for s in src])) + 1   #need this to accomodate max_len = 1\n",
    "        max_tgt_len = min(token_limit, max([len(s) for s in tgt])) + 1\n",
    "        inputs = tokenizer(src, padding='max_length', truncation=True, max_length=max_src_len)\n",
    "        targets = tokenizer(tgt, padding='max_length', truncation=True, max_length=max_tgt_len)\n",
    "        input_ids, input_masks = inputs['input_ids'], inputs['attention_mask']\n",
    "        target_ids, target_masks = targets['input_ids'], targets['attention_mask']\n",
    "        for j in range(len(target_ids)):\n",
    "            target_ids[j].insert(0, 1)\n",
    "            target_masks[j].insert(0, 1)\n",
    "        input_ids, input_masks = torch.tensor(input_ids).to(device), torch.tensor(input_masks).to(device)\n",
    "        target_ids, target_masks = torch.tensor(target_ids).to(device), torch.tensor(target_masks).to(device)\n",
    "        loss = MT_model(input_ids, input_masks, target_ids, target_masks)\n",
    "        total_loss += loss\n",
    "    return total_loss / len(val_loader)\n",
    "        \n",
    "\n",
    "min_val_loss = 10000\n",
    "PATH = 'saved_models/finetune.pt'\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"------------------------EPOCH {epoch + 1}-------------------------------\")\n",
    "    t1 = time.time()\n",
    "    for i, (src, tgt) in enumerate(train_loader):\n",
    "        MT_model.zero_grad()\n",
    "        \n",
    "        max_src_len = min(token_limit, max([len(s) for s in src])) + 1   #need this to accomodate max_len = 1\n",
    "        max_tgt_len = min(token_limit, max([len(s) for s in tgt])) + 1\n",
    "        inputs = tokenizer(src, padding='max_length', truncation=True, max_length=max_src_len)\n",
    "        targets = tokenizer(tgt, padding='max_length', truncation=True, max_length=max_tgt_len)\n",
    "        input_ids, input_masks = inputs['input_ids'], inputs['attention_mask']\n",
    "        target_ids, target_masks = targets['input_ids'], targets['attention_mask']\n",
    "#         print(len(input_ids[0]))\n",
    "        for j in range(len(target_ids)):\n",
    "            target_ids[j].insert(0, 1)\n",
    "            target_masks[j].insert(0, 1)\n",
    "#         print(len(input_ids[0]))\n",
    "#         print(MT_model._model.config.max_position_embeddings)\n",
    "#         print(tgt[0], target_ids[0])\n",
    "        \n",
    "        input_ids, input_masks = torch.tensor(input_ids).to(device), torch.tensor(input_masks).to(device)\n",
    "        target_ids, target_masks = torch.tensor(target_ids).to(device), torch.tensor(target_masks).to(device)\n",
    "        loss = MT_model(input_ids, input_masks, target_ids, target_masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%500 == 0:\n",
    "            t2 = time.time()\n",
    "            val_loss = validation()\n",
    "            if val_loss.item() < min_val_loss:\n",
    "                torch.save(MT_model.state_dict(), PATH)\n",
    "                min_val_loss = val_loss\n",
    "            print(f'Step {i+1} | Val Loss: {val_loss.item():.5f}| Best val loss: {min_val_loss:.5f} | Time: {(t2-t1)/3600 : .4f} hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MT_model.load_state_dict(torch.load('saved_models/finetune.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb049e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_translate(model, device, tokenizer, input_sent):\n",
    "    tok_output = tokenizer(input_sent)\n",
    "    input_ids = tok_output['input_ids']\n",
    "    input_mask = tok_output['attention_mask']\n",
    "    input_ids = torch.tensor(input_ids, device=device)\n",
    "    input_mask = torch.tensor(input_mask, device=device)\n",
    "    target_mask = torch.ones([1, 1], device=device)\n",
    "    past_key_values = model.encode(input_ids, input_mask)\n",
    "#     print(past_key_values[0][0].shape)\n",
    "    start = [1]\n",
    "    gen = []\n",
    "    curr_token = None\n",
    "    while curr_token != 1:\n",
    "        tgt = torch.tensor(start, device=device)    \n",
    "        logits, past_key_values = model.decode(tgt, input_mask, target_mask, past_key_values)\n",
    "#         print(past_key_values[0][0].shape)\n",
    "        logits = model.logSoftmax(logits.unsqueeze(0)).squeeze(0)\n",
    "        value, index = torch.max(logits, dim=1)\n",
    "        curr_token = index[0].item()\n",
    "        gen.append(curr_token)\n",
    "        start = [curr_token]\n",
    "#         print(curr_token, value.item())\n",
    "        target_mask = torch.cat([target_mask, torch.ones([1, 1], device=device)], dim=1)\n",
    "    output_sent = tokenizer.decode(gen)\n",
    "    return output_sent\n",
    "\n",
    "sent = ['What do you want?']\n",
    "greedy_translate(MT_model, device, tokenizer, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e566bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = ['hello']\n",
    "inputs = tokenizer(src, padding='max_length', truncation=True, max_length=1)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc8c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
